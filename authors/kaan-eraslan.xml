<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Yapay Zeka, Derin Öğrenim ve Eski Metinler Üzerine Notlar (Kaan Eraslan tarafından yazılanlar)</title><link>https://d-k-e.github.io/yapayzeka-eski-metinler/</link><description></description><atom:link type="application/rss+xml" href="https://d-k-e.github.io/yapayzeka-eski-metinler/authors/kaan-eraslan.xml" rel="self"></atom:link><language>tr</language><copyright>Contents © 2017 &lt;a href="mailto:kaaneraslan@gmail.com"&gt;Kaan Eraslan&lt;/a&gt; </copyright><lastBuildDate>Fri, 02 Jun 2017 02:06:44 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Makine Öğrenimine Hazırlık 2.1: Doğrusal Cebir- 1.1: Terimler</title><link>https://d-k-e.github.io/yapayzeka-eski-metinler/posts/makine-ogrenimine-hazirlik-21-dogrusal-cebir-1/</link><dc:creator>Kaan Eraslan</dc:creator><description>&lt;div&gt;&lt;p&gt;Merhaba arkadaşlar,&lt;/p&gt;
&lt;p&gt;Bundan önceki, Derin Öğrenime Giriş &lt;a class="reference external" href="https://d-k-e.github.io/yapayzeka-eski-metinler/posts/yapay-zeka-ve-derin-ogrenime-giris-1/"&gt;yazı dizisinde&lt;/a&gt;, çok kabaca derin öğrenimin ne olduğundan, ne tip modeller kullandığından, ilgilendiği problemlerden ve bu problemlere sunduğu çözümlerden bahsettim.
Bu yazı dizisini ise Derin Öğrenim algoritmalarını açıklarken kullanacağım matematiksel alt yapıya ayırdım.
Bu alt yapının ilk ayağı hiç kuşkusuz doğrusal cebir. Doğrusal cebiri üniversitede görmeseler de liseden hatırlayanlar olacaktır.
Koordinat sistemi x,y filan deyince aklınıza gelen şey.
Bu yazı tabi ki doğrusal cebir ilgili bilinen her şeyi anlatmaya filan çalışmayacak, derin öğrenim ve daha genel anlamda makine öğreniminde kullanıldığı kadarını sizlerle paylaşmaya çalışacağım.&lt;/p&gt;
&lt;p&gt;Şimdi ağırlıklı olarak kullanacağımız terimler şunlar: sayıllar, dizeyler, yöneyler, gereyler.
Bu terimlerin her birini en ufak detayına kadar uzun uzun anlatacağım, zira ne ifade ettiklerini tam olarak bilmek şart.&lt;/p&gt;
&lt;div class="section" id="sayillar"&gt;
&lt;h2&gt;Sayıllar&lt;/h2&gt;
&lt;p&gt;Sayıl, bir adet sayıdır. Böyle deyince garip duyuluyor, ancak bunun dışında göreceğimiz diğer terimler genellikle daha karmaşık kümelerden oluşuyorlar.
Sayıl öyle değil, bildiğimiz normal 3,4,7 filan gibi bir sayı.
Genellikle hangi sayı kümesine ait olduğu da belirtilir.
Örneğin Sayıl "a" &lt;span class="math"&gt;\(s \in \mathbb{N}\)&lt;/span&gt; yani s elemanıdır doğal sayılar kümesinin.
Nerede işimize yarıyacak ?
Yöneylerin arasındaki açı ilişkilerini incelerken, bir dizeyi bir başka dizeye dönüştürürken, vs.
Özellikle temel bileşen analizi gibi algoritmalarda özyöneyleri incelerken bu sayıl terimi anahtar kavramlardan biri olacak.
Daha doğrusu ben bu terimi bildiğinizi varsayarak algoritmayı açıklayacağım.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="yoneyler"&gt;
&lt;h2&gt;Yöneyler&lt;/h2&gt;
&lt;p&gt;Yöneyler, adının da belirttiği gibi, yönü ve büyüklüğü olanlar.
Bunlar genellikle &lt;em&gt;belirli bir referans noktasına göre&lt;/em&gt;, ki bu genelde kolaylık olsun diye (0,0) kabul edilir, başka bir noktada olan noktalardır.
Referans noktasıyla, tayin ettikleri nokta arasındaki mesafe onların büyüklüğünü oluşturur.
Yöneyin, yönünüyse eksenlerle yaptıkları açılara göre söylenir. Örnek verecek olursak:&lt;/p&gt;
&lt;img alt="/images/MÖ-Hazırlık-21/yöneyÖrneği.png" src="https://d-k-e.github.io/yapayzeka-eski-metinler/images/M%C3%96-Haz%C4%B1rl%C4%B1k-21/y%C3%B6ney%C3%96rne%C4%9Fi.png"&gt;
&lt;p&gt;&lt;a class="footnote-reference" href="https://d-k-e.github.io/yapayzeka-eski-metinler/posts/makine-ogrenimine-hazirlik-21-dogrusal-cebir-1/#id4" id="id1"&gt;[2]&lt;/a&gt;
Resimdeki "a" yöneyimizin &lt;em&gt;vardığı&lt;/em&gt; dolayısıyla onu tayin eden noktayı belirtiyor.
63° olarak belirtilen yöneyin yönü.
Doğru olarak çizilen alansa yöneyin büyüklüğünü temsil ediyor.&lt;/p&gt;
&lt;p&gt;Yöneyler açık olarak ifade edildiklerinde genelde şu şekilde yazılırlar.
Diyelim ki elimizde bir "a" yöneyi olsun &lt;span class="math"&gt;\(a = [a_1, a_2, a_3,{\dots}, a_n ]\)&lt;/span&gt;.
"a"'nın altına yazılanlar elemanların numarası, yani a yöneyinin birinci elemanı, ikinci elemanı, gibi.
Bazı kitaplarda A noktasından B noktasına doğru olan bir yöney için &lt;span class="math"&gt;\(\vec{AB}\)&lt;/span&gt; gibi ifadeler de kullanılıyor.
Bazen yöneyi dikine yazdıklarını da gördüm. Örneğin:&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
a = \left[
\begin{array}{r}
 a_1 \\
 a_2 \\
 a_3 \\
 \vdots \\
 a_n
 \end{array}
\right]
\end{equation*}
&lt;/div&gt;
&lt;p&gt;Yöneylerin dizinlenmesinde kullanılan bir takım uzlaşımlar var.
Örneğin, yöneyin ikinci, beşinci ve yirmi sekizinci elemanlarını ayırmak istersek, bunun için başta bu eleman numaralarının olduğu bir küme oluşturuyoruz.
Örneğin "k" kümesi, yani &lt;span class="math"&gt;\(k = { 2, 5, 28 }\)&lt;/span&gt;.
Sonrasında da bu kümenin adını tıpkı diğer elemanları ifade ederken kullandığımız gibi yöneyin adının altına koyuyoruz, yani &lt;span class="math"&gt;\(a_k\)&lt;/span&gt;.
Hariç olan elemanları kast ettiğimizde eksi işaretini kullanıyoruz.
Örneğin ikinci elemanlar hariç, yöneyin bütün elemanları gibi bir ifade, şöyle oluyor &lt;span class="math"&gt;\(a_{-2}\)&lt;/span&gt;.
"k" kümesine dahil olmayan elemanların hepsi gibi ifadeler de yine benzer bir şekilde &lt;span class="math"&gt;\(a_{-k}\)&lt;/span&gt; ifade ediliyor.&lt;/p&gt;
&lt;!-- yöneylerin dizinlenmesi sayfa 32, resmi küçült renklerini değiştir --&gt;
&lt;/div&gt;
&lt;div class="section" id="dizeyler"&gt;
&lt;h2&gt;Dizeyler&lt;/h2&gt;
&lt;p&gt;Dizeyler bayağı meşhur, filmini bile çektiler. İsminden anlaşılacağı üzere yatay ve dikey dizilerden oluşan, dolayısıyla iki boyutlu, sayı dizinidir.
Genellikle boyutları y x d ifadesiyle verilir.
Bu ifade y, satıra, d sütun olarak okunur &lt;a class="footnote-reference" href="https://d-k-e.github.io/yapayzeka-eski-metinler/posts/makine-ogrenimine-hazirlik-21-dogrusal-cebir-1/#id3" id="id2"&gt;[1]&lt;/a&gt;.
Örneğin 23 satırlı ve 4 sütunlu bir K dizeyi için kullanılan ifade şudur: &lt;span class="math"&gt;\(K^{23x4}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Dizeyler ve onlarla ilgili işlemler Makine Öğreniminde çok sık kullanılıyor, bundan dolayıdır ki numpy, scipy filan gibi kütüphaneler, dizey işlemlerini eniyilemek için bir hayli uğraşıyorlar.
Dizeydeki bir elemanı ifade etmek istediğimizde onun satır ve sütun numarasını veririz&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Örneğin &lt;span class="math"&gt;\(K_{12,2}\)&lt;/span&gt; ifadesi K dizeyinin 12. satırı üzerinde 3. sütunun altına denk gelen elemanı ifade etmektedir.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Bir &lt;strong&gt;satırdaki&lt;/strong&gt; elemanların tamamını ifade etmek istediğimiz zaman sütun numarası yerine ":" koyulur.&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Örneğin &lt;span class="math"&gt;\(K_{3,:}\)&lt;/span&gt; ifadesi K dizeyinin 3. satırındaki bütün elemanları ifade eder.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Bir &lt;strong&gt;sütundaki&lt;/strong&gt; elemanların tamamını ifade etmek istediğimiz zaman satır numarası yerine ":" koyulur.&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Örneğin &lt;span class="math"&gt;\(K_{:,3}\)&lt;/span&gt; ifadesi K dizeyinin 3. sütunundaki bütün elemanları ifade eder.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Bazı durumlarda dizeyde erişmek istediğimiz elemanlar bir ifadenin sonucudurlar.
İfadeden kastım, 3'ün katı olan satırların 2.sinden 3. sütuna tekabül eden eleman gibi şeyler.
Bunlar genelde &lt;span class="math"&gt;\(f(K)_{y,d}\)&lt;/span&gt; şeklinde temsil edilir.
Bu ifade şu şekilde okunur, K dizeyine f işlemini yap, oradaki satır ve sütunu al.
f işleminden kastım, yukarıdaki 3'ün katı filan muhabbeti gibi olan ifadeler.
Tam öyle olmak zorunda değil tabi ama ona benzer dizey değerlendirmesi yapan ifadeler.&lt;/p&gt;
&lt;p&gt;Sıklıkla bahsedeceğimiz dizey işlemleri şunlar: dizey toplamı, sayıl çarpımı, dizey çaprazlama, dizey çarpımı.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="gereyler"&gt;
&lt;h2&gt;Gereyler&lt;/h2&gt;
&lt;p&gt;Gereyler aslında dizeyler gibi, sadece çok boyutlular.
Nasıl K dizeyindeki bir elemanı tayin etmek için eksenler üzerindeki konumunu K'nin altına yazıyorduk, gereylerde de benzer bir sistem var.
Örneğin 7 boyutlu, yani eksenli bir G gereyindeki elemanı belirtmek için şöyle bir ifade kullanırız &lt;span class="math"&gt;\(G_{j,o,r,m,v,r,x}\)&lt;/span&gt;, tabi burada j, o, r, m, v, ve x'in, sayma sayıları kümesinin elemanı olduğunu kabul ediyoruz.&lt;/p&gt;
&lt;p&gt;Bu yazıyı burada bitiriyorum.
Gördüğümüz matematiksel kavramlar bundan sonrası için temel teşkil ediyor.
Bir sonraki yazıda bunlarla yapılan işlemleri anlatmaya çalışacağım.
Anlaşılmayan bir şey varsa, ya da eklemek istediğiniz bir şey varsa lütfen yorumlarda belirtin.&lt;/p&gt;
&lt;p&gt;Sağlıcakla,&lt;/p&gt;
&lt;p&gt;Kaan&lt;/p&gt;
&lt;div class="section" id="notlar"&gt;
&lt;h3&gt;Notlar&lt;/h3&gt;
&lt;table class="docutils footnote" frame="void" id="id3" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label"&gt;&lt;col&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="https://d-k-e.github.io/yapayzeka-eski-metinler/posts/makine-ogrenimine-hazirlik-21-dogrusal-cebir-1/#id2"&gt;[1]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;y, yi yatay, d'yi dikey gibi de okuyabilirsiniz, yani yataya dikey.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id4" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label"&gt;&lt;col&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="https://d-k-e.github.io/yapayzeka-eski-metinler/posts/makine-ogrenimine-hazirlik-21-dogrusal-cebir-1/#id1"&gt;[2]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;Resimin temeli Jakob Scholbach'a aittir, üzerindeki değişiklikler bana ait, &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Vector_space#/media/File:Vector_components.svg"&gt;orjinali&lt;/a&gt;.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;</description><category>dizey</category><category>gerey</category><category>makine öğrenimi</category><category>mathjax</category><category>sayıl</category><category>yöney</category><guid>https://d-k-e.github.io/yapayzeka-eski-metinler/posts/makine-ogrenimine-hazirlik-21-dogrusal-cebir-1/</guid><pubDate>Mon, 29 May 2017 23:53:12 GMT</pubDate></item><item><title>Yapay Zeka ve Derin Öğrenime Giriş 1.3</title><link>https://d-k-e.github.io/yapayzeka-eski-metinler/posts/yapay-zeka-ve-derin-ogrenime-giris-13/</link><dc:creator>Kaan Eraslan</dc:creator><description>&lt;div&gt;&lt;p&gt;Merhaba Arkadaşlar,&lt;/p&gt;
&lt;p&gt;Bir &lt;a class="reference external" href="https://d-k-e.github.io/yapayzeka-eski-metinler/posts/yapay-zeka-ve-derin-ogrenime-giris-2/"&gt;önceki yazımda&lt;/a&gt; &lt;em&gt;Temsil Öğrenimi&lt;/em&gt; veya diğer bir adıyla &lt;em&gt;Nitelik Öğrenimi&lt;/em&gt; konusuna değinmiştim.
Otomatik kodlayıcıların aldıkları işlevlerden ve temsilde açığa çıkan değişiklik unsurlarıyla, gözlemlenenlerin ayrıştırıcı özellikleri arasındaki ilişkiden bahsetmiştim.
Ayrıştırıcı özelliklerin arasındaki karşılıklı etkileşim dolayısıyla temsil öğrenimindeki aşılması güç gözüken bir sorun olan değişiklik unsurlarının birbirinden ayrıştırılması işlemini açıklamaya çalıştım.&lt;/p&gt;
&lt;p&gt;Bu yazıda, önceki yazıda duyurduğum gibi &lt;em&gt;Derin Öğrenimin&lt;/em&gt; bahsettiğim kavramlarla ilişkisine ve yukarıda belirttiğim probleme nasıl bir çözüm getirdiğine değineceğim.
Bu giriş yazı dizisinin son yazısı olduğu için, kavramlarla aşina olmayanlar için serinin ilk iki yazısına da göz atmalarını tavsiye ederim, aksi takdirde bazı şeyler havada kalacaktır.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Derin Öğrenimin&lt;/em&gt; yaptığı karmaşık temsilleri daha basit temsiller cinsinden ifade etmeye çalışmaktır.
Örneğin, beyaz bir tahtaya çizilmiş bir üçgeni düşünelim.
Üçgene baktığımızda gördüğümüz önce beyazdan farklı olandır.
Sonrasında bu farklı olanın düz çizgilerden oluştuğunu fark ederiz.
Ardından bu düz çizgilerin köşeler oluşturduğunu fark ederiz.
Nihayetinde oluşan köşelerin sayısı bize üçgeni verir.
Bu işleyiş derin öğrenim sürecinde makinenin işleyişine benzerdir.
Makine başta imgecik değerlerinden, beyaz olmayanları gruplar.
Sonrasında gruplananların pozisyonlarını karşılaştırarak alarak onların kenar mı köşe mi olduğunu belirler.
Son olarak da köşe sayısını hesaplar ve ilgili köşe sayısına tekabül ettiği kendisine verilmiş sonucu size sunar.&lt;/p&gt;
&lt;p&gt;O halde fark etmiş olabileceğiniz üzere burada işleyen imgecik değerlerinde açıkça gözlemediğimiz 4-5 tane kavram var.
Siyah, beyaz, düz çizgi, kenar, köşe, köşe sayısı.
Siyahı, beyaz olmayan diyerek, ve imgecik değerlerindeki farklılıktan yakaladık diyelim.
Beyaz olmayan imgeciklerin düz bir çizgi oluşturduğunu ifade edebilmemiz için, bu imgeciklerin konumu hakkında bize yargı veren bir model olması lazım.
Bu açıkça görüldüğü üzere ne üçgenle ne de imgeciklerin kendisiyle doğrudan ilişkili bir yapı, sadece belirli konumlarda olanların düz olmaya tekabül ettiğini belirten bir model.
Bu modelin elimizdeki üçgen problemine uygulanışında modele sunulan imgeciklerin konumu, ancak salt model açısından bakıldığında konumu verilen araba tekerleği, havadaki uçaklar, ya da endoplazmik retikulumlarda olabilirdi.
Aynı durum kenar, köşe kavramları içinde geçerli, yani bunlar da üçgen mahsus olmayan, imgeciklerle de doğrudan bir bağlantısı olmayan kavramlar.
Eldeki örnekte düz çizgilerin başladıkları ve bittikleri yerler olarak tanımlanıyor olmalarında ne üçgene ne de imgeciklere mahsus bir durum var.
Buna karşın, köşe sayısı ve üçgen arasındaki ilişki bir hayli doğrudan. O kadar ki bunun üçgen üzerinden modellenmiş bir nitelik olduğu fark ediliyor.
Makine elimizdeki örnekte bahsettiğimiz aşamalardan geçerek ne yapmış oldu peki ?
Çok basit, modeller arasındaki bir hiyerarşiyi takip ederek, yani onların ilgilendiği değerlerin hesaplanışında bir öncelik sonralık ilişkisi güderek, örneğin, önce siyah-beyaz, sonra çizgi, sonra kenar-köşe, vs. gibi, ham veriden, yani imgeciklerden, yakalamak istediğimiz varlığın ayrıştırıcı özelliğini, üç köşeli olmak, buldu.&lt;/p&gt;
&lt;p&gt;Bu yaklaşımdaki esas nokta, farklı modeller tarafından hesaplanan sonuçların daha sonra kendilerine atıfta bulunulabilecek şekilde saklanmaları, bu sistemin kendi kendisini değerlendirebilmesini sağlayan yegane özellik.
Elimizdeki örnekte fark etmesi birazcık zor olmakla birlikte, diyelim ki ABC üçgeninin BC kenarının ortasında ufak bir boşluk var.
Silgi çarpmış, kolumuz değmiş, vs. herhangi bir şey olabilir.
Bu şartlar altında, üçgeni yakalamaya çalışan sistemimizin bu durumda çalışmaya devam etmesi, ve o boşluğu, kenarların ortasındaki boşluk olarak temsil edebilmesi lazım.
Modellerin sonuçlarının atıfta bulunulabilmesi burada devreye giriyor.
Elimizdeki örnekte makine diyelim ki düz çizgileri saptadı, ortaya açık bir şekil çıktı, dolayısıyla kenar diye bir şeyden söz edemememiz lazım.
Daha sonraki aşamada makine köşeleri ve köşe sayısını hesapladı ve şeklin üç köşe sayısı şartını sağladığını hesapladı.
Bu hesap ışığında makine, daha önceki model tarafından verilen açık şekil olmak sonucuna tekrar dönebilir, ve açıklık belirten değişiklik unsurunu, makineye daha öncesinden verdiğimiz talimatlar ışığında, görmezden gelebilir, veya bu sonucun kapsamını daraltabilir, yani örneğin şekil açıktır yerine çizgi bir nokta da kesilmiştir sonucunu sunabilir vs.&lt;/p&gt;
&lt;p&gt;Bu yöntemin derin öğrenim olarak ifade edilmesinin sebebi de, girdideki temsil ile çıktıdaki temsil arasında birbirinden görece bağımsız modeller tarafından üretilen temsillerin olması.
Derin Öğrenim algoritmalarını birer merdiven olarak da düşünebilirsiniz.
Her basamak aslında bir basamak, o basamağı bir başka basamağın üstüne ya da altına koyduğunuz için yukarıya ya da aşağıya doğru giden bir basamak. Kendi başına bıraksanız, yani merdivenden çıkarsanız basamağı ve yere koysanız, öyle ufak bir yükselti olur.&lt;/p&gt;
&lt;p&gt;Derin öğrenim modellerinin, derinlik ölçümü için kullanılan, temelde iki yaklaşım var.
Birincisi, bir derin öğrenim modelinin değerlendirilebilmesi için gerekli talimatların uzunluğu.
İkincisiyse, birbirleriyle ilişkilenen kavramların temsilini sunan çizgenin derinliği.
İlki hangi işlemin adım olarak sayılacağına göre değişiklik gösterir.
Kullandığımız modellerden birinin K-Ortalamalar Kümesi algoritması olduğunu düşünelim.
Bu algoritma bilindiği üzere aslında iki aşamalıdır: Merkezlere eleman tayin etme ve elemanların pozisyonlarını eniyileme.
Birinci kriter ışığında derinliğimiz bu iki aşamayı ayrı ayrı saymak ya da bu iki aşamayı aynı algoritmaya tabi olduğu için bir olarak saymak bağlamında değişiklik gösterecektir.
İkinci kriterle konuya yaklaşıldığı zamansa ortaya yukarıda üçgen için tarif ettiğim modele benzer bir model ortaya çıkıyor.
Elimizde, örneğin, düz çizgi, kenar, köşe gibi kavramlar var ve derinlik bunların birbiriyle olan ilişkilerini temsil eden çizgede gözleniyor.
Bu yaklaşımdaki dikkat edilmesi gereken noktaysa, kavramlar arasındaki ilişkilerden çıkan çizgedeki derinliğin, hesaplanma sürecini ifade eden çizgenin derinliğinden bir hayli farklı olması.&lt;/p&gt;
&lt;p&gt;Bu iki yaklaşımın ikisi de eşit derecede doğru ve geçerli, zira kişiler kendi modellerini kurgularken farklı birimleri temel alıyorlar.
Bir modelin derin olarak adlandırılabilmesi için de uzlaşılagelmiş bir ölçüm yok. O halde &lt;em&gt;Derin Öğrenim&lt;/em&gt; nedir ?
Tek cümleyle özetleyecek olursak, derin öğrenim, dünyayı içiçe geçmiş hiyerarşik temsiller şeklinde kurgulayarak karmaşık kavram ve temsilleri, daha basit kavram ve temsiller aracılığıyla hesaplayan, makine öğrenimi alanıdır.&lt;/p&gt;
&lt;p&gt;Bu yazıyı burada noktalıyorum ve böylelikle Derin Öğrenime Giriş serisini tamamlamış oluyorum.
Bundan sonraki seri, derin öğrenim algoritmalarını anlamak için olmazsa olmaz olan doğrusal cebir üzerine olacak.
Anlaşılmayan, ya da çok açık gözükmeyen noktaları lütfen yorumlarda belirtin.
Elimden geldiğince açıklamaya çalışırım.&lt;/p&gt;
&lt;p&gt;Sağlıcakla,&lt;/p&gt;
&lt;p&gt;Kaan&lt;/p&gt;&lt;/div&gt;</description><category>derin-öğrenim</category><category>makine öğrenimi</category><category>yapay-zeka</category><guid>https://d-k-e.github.io/yapayzeka-eski-metinler/posts/yapay-zeka-ve-derin-ogrenime-giris-13/</guid><pubDate>Sun, 28 May 2017 01:52:32 GMT</pubDate></item><item><title>Yapay Zeka ve Derin Öğrenime Giriş 1.2</title><link>https://d-k-e.github.io/yapayzeka-eski-metinler/posts/yapay-zeka-ve-derin-ogrenime-giris-2/</link><dc:creator>Kaan Eraslan</dc:creator><description>&lt;div&gt;&lt;p&gt;Merhaba Arkadaşlar,&lt;/p&gt;
&lt;p&gt;Daha &lt;a class="reference external" href="https://d-k-e.github.io/yapayzeka-eski-metinler/posts/yapay-zeka-ve-derin-ogrenime-giris-1/"&gt;önceki yazımda&lt;/a&gt;, yapay zeka çalışmalarında Derin Öğrenime gelene kadar kullanılagelmiş yöntem ve yaklaşımların kısa bir özetini yapmıştım. En son gelinen noktada, makine öğrenimi için gereken temsilde nitelik oluşturma zorunluluğuna kırmızı ışıkta geçen arabaların plakasını yakalamak problemi üzerinden değinmiştim.&lt;/p&gt;
&lt;p&gt;Aynı örnek üzerinden devam edecek olursak, nitelikleri üretmenin/ayrıştırmanın &lt;em&gt;en doğru&lt;/em&gt; veya &lt;em&gt;en geçerli&lt;/em&gt; yolu yok. Ne özelliği yakalamanızı sağlıyorsa o geçerli, doğru yol, ancak şu var, el ile bu nitelikleri yaratmak çok vakit isteyen bir şey.
Elimizdeki örnek için elle ilgili niteliği kurgulamaya çalışsak, plakayı oluşturması muhtemel imgecik serilerini, kameranın aracı resmin kaçta kaçına taşıdığına göre, plakanın büyüklüğünün sabit olduğu düşünülürse, plakanın resimde olabileceği alanlarda, eşleştirmeye çalışırdık.
Böyle deyince çok zor duyulmuyor olabilir, özellikle bilgisayarla görüş alanındaki kütüphanelerin çokluğu düşünülürse, ancak şunu belirtmek zorundayım 'plakayı oluşturması muhtemel imgecik serileri' ifadesini el ile oluşturmak mümkün değil, zira temsilinizi değiştiren çok fazla özellik dışı etmen var.
Örneğin, yazın güneş tam kameranın arkasından vurdu, plakanın beyazı parladı bazı harfler silüet gibi görünüyor, veya kırsal alan, araba çamura girmiş plakanın bir kısmına çamur bulaşmış, veya kamyonun kasası plakaya gölge ediyor, bu yüzden plaka tam beyaz gibi gözükmüyor, vs gibi özelliğe dair olmayan bir sürü etmen özelliği değiştiriyor. Dolayısıyla, özelliğin temsili de beklenen değerlerde olmuyor.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Temsil Öğrenimi&lt;/em&gt; &lt;a class="footnote-reference" href="https://d-k-e.github.io/yapayzeka-eski-metinler/posts/yapay-zeka-ve-derin-ogrenime-giris-2/#id4" id="id1"&gt;[1]&lt;/a&gt; ya da diğer adıyla &lt;em&gt;Nitelik Öğrenimi&lt;/em&gt; denen yaklaşım, bu soruna çare bulmaya çalışıyor.
Bu yaklaşımı temsilin temsillerini üretmek gibi de düşünebilirsiniz.
Örneğin, elimizdeki ışıkta geçen araba resmine bakalım. Resim, bir imgecikler bütün dedik.
Bu imgecikler bütününü örneğin aynı değere sahip olanların koordinat düzlemindeki pozisyonları kümesi olarak da temsil edebiliriz.
Bu bir çeşit veri çerçevesi olacaktır. Çerçevenin sütunları imgecik değerleri, satırları da bir koordinat noktaları olacaktır.
Kullanılan imgecik değerlerinin yayılma aralığını verir.
Tek başına bu bile resmin içinde bulunduğu şartlara dair önemli tiyolar barındıracaktır.
Resim daha sonrasında koordinatlar sütun, imgecik değerleri satır olarak temsil edilebilir.
Bu sütunlar plakanın standard büyüklüğüne göre gruplanıp, benzer değerlerde seyreden satırların uzunluğuna bakılarak, plakanın bulunduğu koordinatlar saptanabilir, zira plakanın beyaz başladığı düşünülürse, koordinatlar değişse bile imgeciklerin değerleri belirli bir aralıkta seyredecektir. Yani bu olması beklenen şey.
Yukarıda belirttiğim gibi özellik dışı etmenler, işlerin bu kadar düzgün yürümemesi sağlayacaktır, ancak şu önemli, buraya kadar tarif ettiğim her şey bir makine tarafından yapılabilir.
Yapması gereken tek şey, ham maddeyi çeşitli temsillere dönüştürmek ve bu temsillerde tekrar eden kalıpları yakalamak. Bu çok katmanlı bir temsil grubu olarak kurgulanabilir.&lt;/p&gt;
&lt;p&gt;Bu çok katmanlı temsil grubunu oluşturmakta kullanılan tipik algoritma, otomatik kodlayıcılardır &lt;a class="footnote-reference" href="https://d-k-e.github.io/yapayzeka-eski-metinler/posts/yapay-zeka-ve-derin-ogrenime-giris-2/#id5" id="id2"&gt;[2]&lt;/a&gt;.
Yukarıda tarif ettiğim şablonda otomatik kodlayıcılar temsiller arası geçişleri sağlayanlardır.
Genellikle çift yönlüdürler. Kabaca bir kodlayıcı ve bir de çözücü içerirler.
Kodlayıcı gelen girdiyi bir başka temsile dönüştürür, çözücü de yeni oluşan temsili kodlayıcıya geldiği haline dönüştürür.
Genelde kodlayıcılar belirli niteliklileri oluşturacak şekilde alıştırılırlar.
Burada temel amaç tabi değişiklik unsurlarını &lt;a class="footnote-reference" href="https://d-k-e.github.io/yapayzeka-eski-metinler/posts/yapay-zeka-ve-derin-ogrenime-giris-2/#id6" id="id3"&gt;[3]&lt;/a&gt; yakalamak.
Bu unsurlar, temsilde gözlemlenen olgunun ayrıştırıcı özelliklerine tekabül ederler.
Ayrıştırıcı özellikler, temelde bir varlığı diğer varlıktan ayırmamızı veya onunla gruplamamızı sağlayanlar.
Bundan çok acayip şeyler anlamaya gerek yok, örneğin masanın ayrıştırıcı özelliği nedir, ya da onu üzerindeki lambadan nasıl ayırıyoruz ?
Masanın dört ayağı var, düz bir yüzeyi var, vs, lambanın yuvarlak bir tabanı ve bir kablosu var, vs.
Bu ve bunlar gibi özellikler masayı lambadan ayırmamızı sağlayan unsurlar.
Temsil üzerinde bu unsurları yakalamak, yapay zekanın gerçek dünya da iş yapabilmesinin temel gerekliliklerinden biri.&lt;/p&gt;
&lt;p&gt;Sorun şu, gerçek dünyadaki gözlemlenenlerin çok fazla ayrıştırıcı özelliği var, dahası bir sürü gözlemlenenin ayrıştırıcı özelliği başka gözlemlenenlerin ayışrtırıcı özellikleriyle etkileşime giriyor.
Bu karşılıklı etkileşim hali, bize değişiklik unsurlarının birbirinden ayrılmasını zorunlu kılıyor.
İnsan bu ayrımı otomatik olarak yapıyor, örneğin ışığın üzerine vurduğu açı değiştiği zaman, insan masanın masa olarak kalmaya devam ettiğinin ayırdına varabiliyor, ancak baktığın şeyin ne olduğundan habersiz makineler için bu durumun bir garantisi yok.
Dolayısıyla bilgisayarlar için masanın masa olarak temsilde belirmesini sağlayan değişiklik unsurlarının, masaya vuran ışığın değişiklik unsurlarından ayrılabilmesi gerekli.
Bu temsil öğreniminin derin öğrenim yöntemleri olmaksızın tıkandığı noktalardan biri, zira bu iki değişiklik unsurunu birbirinden ayıracak olanın saptanması temsile dair neredeyse insan düzeyinde bir anlamayı varsayıyor.
Masanın üstüne vuran ışık örneğinden gidecek olursak, mevcut durumda masanın üstüne vuran ışıktan ayrıştırılabilmesi için, masayı oluşturan imgeciklerin ışık değiştikçe nasıl değer değiştirdiklerini biliyor olmamız lazım.
Örnek izole edildiğinde yapılabilir gözükse de, gerçek dünyadaki, masanın üstünde duran başka şeyler olabileceği, ışığın örneğin doğrudan değilde başka bir objeye vurarak masaya yansıdığı vs gibi durumlar düşünüldüğünde nitelik öğreniminin unsurlar arasında bir hiyerarşi kurmaksızın, bahsettiğim soruna çözüm getirebilmesi mümkün gözükmüyor.&lt;/p&gt;
&lt;p&gt;Bu yazıyı burada noktalıyorum. Bir &lt;a class="reference external" href="https://d-k-e.github.io/yapayzeka-eski-metinler/posts/yapay-zeka-ve-derin-ogrenime-giris-13/"&gt;sonraki yazı&lt;/a&gt; giriş bölümünün son yazısı olacak. O yazıda &lt;em&gt;Derin Öğrenimin&lt;/em&gt; bahsettiğim kavramlarla olan ilişkisine, ve &lt;em&gt;derinliğin&lt;/em&gt; nereden geldiğine değineceğim. Son olarak da model derinliğinin ölçülmesinde kullanılan yöntemlerden kısaca bahsedeceğim.&lt;/p&gt;
&lt;p&gt;Sağlıcakla,&lt;/p&gt;
&lt;p&gt;Kaan&lt;/p&gt;
&lt;!-- Sayfa 5 deep learning bölümünde kaldın devam et oradan --&gt;
&lt;div class="section" id="terimler"&gt;
&lt;h2&gt;Terimler&lt;/h2&gt;
&lt;table class="docutils footnote" frame="void" id="id4" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label"&gt;&lt;col&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="https://d-k-e.github.io/yapayzeka-eski-metinler/posts/yapay-zeka-ve-derin-ogrenime-giris-2/#id1"&gt;[1]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;Temsil Öğrenimi: Ham verinin temsilinde özelliği ayrıştıracak niteliği elle oluşturmaktansa, makinenin bu nitelikleri oluşturması süreci.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id5" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label"&gt;&lt;col&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="https://d-k-e.github.io/yapayzeka-eski-metinler/posts/yapay-zeka-ve-derin-ogrenime-giris-2/#id2"&gt;[2]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;Otomatik Kodlayıcılar: Genelde Kodlayıcı ve Çözücüden oluşan, temsilden nitelikli temsiller türetmeye ve türetilen temsillerden önceki hallerine dönmeye yarayan algoritmaların genel adı.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id6" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label"&gt;&lt;col&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="https://d-k-e.github.io/yapayzeka-eski-metinler/posts/yapay-zeka-ve-derin-ogrenime-giris-2/#id3"&gt;[3]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;Değişiklik unsurları: Bu unsurlar, gözlemlenenin gözlemlendiği halini oluşturduğu kabul edilen etmenler. Örneğin bir araba plakasının değişiklik unsurları, siyahlık, beyazlık, köşeli olmak, düz çizgili olmak, eğrilere sahip olmak, vs gibidir.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;&lt;/div&gt;</description><guid>https://d-k-e.github.io/yapayzeka-eski-metinler/posts/yapay-zeka-ve-derin-ogrenime-giris-2/</guid><pubDate>Fri, 26 May 2017 02:49:35 GMT</pubDate></item></channel></rss>