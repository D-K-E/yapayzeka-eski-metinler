<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Yapay Zeka, Derin Öğrenim ve Eski Metinler Üzerine Notlar (yapay-zeka ile ilgili yazılar)</title><link>https://d-k-e.github.io/yapayzeka-eski-metinler/</link><description></description><atom:link type="application/rss+xml" href="https://d-k-e.github.io/yapayzeka-eski-metinler/categories/cat_yapay-zeka.xml" rel="self"></atom:link><language>tr</language><copyright>Contents © 2017 &lt;a href="mailto:kaaneraslan@gmail.com"&gt;Kaan Eraslan&lt;/a&gt; </copyright><lastBuildDate>Fri, 02 Jun 2017 02:06:44 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Makine Öğrenimine Hazırlık 2.1: Doğrusal Cebir- 1.1: Terimler</title><link>https://d-k-e.github.io/yapayzeka-eski-metinler/posts/makine-ogrenimine-hazirlik-21-dogrusal-cebir-1/</link><dc:creator>Kaan Eraslan</dc:creator><description>&lt;div&gt;&lt;p&gt;Merhaba arkadaşlar,&lt;/p&gt;
&lt;p&gt;Bundan önceki, Derin Öğrenime Giriş &lt;a class="reference external" href="https://d-k-e.github.io/yapayzeka-eski-metinler/posts/yapay-zeka-ve-derin-ogrenime-giris-1/"&gt;yazı dizisinde&lt;/a&gt;, çok kabaca derin öğrenimin ne olduğundan, ne tip modeller kullandığından, ilgilendiği problemlerden ve bu problemlere sunduğu çözümlerden bahsettim.
Bu yazı dizisini ise Derin Öğrenim algoritmalarını açıklarken kullanacağım matematiksel alt yapıya ayırdım.
Bu alt yapının ilk ayağı hiç kuşkusuz doğrusal cebir. Doğrusal cebiri üniversitede görmeseler de liseden hatırlayanlar olacaktır.
Koordinat sistemi x,y filan deyince aklınıza gelen şey.
Bu yazı tabi ki doğrusal cebir ilgili bilinen her şeyi anlatmaya filan çalışmayacak, derin öğrenim ve daha genel anlamda makine öğreniminde kullanıldığı kadarını sizlerle paylaşmaya çalışacağım.&lt;/p&gt;
&lt;p&gt;Şimdi ağırlıklı olarak kullanacağımız terimler şunlar: sayıllar, dizeyler, yöneyler, gereyler.
Bu terimlerin her birini en ufak detayına kadar uzun uzun anlatacağım, zira ne ifade ettiklerini tam olarak bilmek şart.&lt;/p&gt;
&lt;div class="section" id="sayillar"&gt;
&lt;h2&gt;Sayıllar&lt;/h2&gt;
&lt;p&gt;Sayıl, bir adet sayıdır. Böyle deyince garip duyuluyor, ancak bunun dışında göreceğimiz diğer terimler genellikle daha karmaşık kümelerden oluşuyorlar.
Sayıl öyle değil, bildiğimiz normal 3,4,7 filan gibi bir sayı.
Genellikle hangi sayı kümesine ait olduğu da belirtilir.
Örneğin Sayıl "a" &lt;span class="math"&gt;\(s \in \mathbb{N}\)&lt;/span&gt; yani s elemanıdır doğal sayılar kümesinin.
Nerede işimize yarıyacak ?
Yöneylerin arasındaki açı ilişkilerini incelerken, bir dizeyi bir başka dizeye dönüştürürken, vs.
Özellikle temel bileşen analizi gibi algoritmalarda özyöneyleri incelerken bu sayıl terimi anahtar kavramlardan biri olacak.
Daha doğrusu ben bu terimi bildiğinizi varsayarak algoritmayı açıklayacağım.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="yoneyler"&gt;
&lt;h2&gt;Yöneyler&lt;/h2&gt;
&lt;p&gt;Yöneyler, adının da belirttiği gibi, yönü ve büyüklüğü olanlar.
Bunlar genellikle &lt;em&gt;belirli bir referans noktasına göre&lt;/em&gt;, ki bu genelde kolaylık olsun diye (0,0) kabul edilir, başka bir noktada olan noktalardır.
Referans noktasıyla, tayin ettikleri nokta arasındaki mesafe onların büyüklüğünü oluşturur.
Yöneyin, yönünüyse eksenlerle yaptıkları açılara göre söylenir. Örnek verecek olursak:&lt;/p&gt;
&lt;img alt="/images/MÖ-Hazırlık-21/yöneyÖrneği.png" src="https://d-k-e.github.io/yapayzeka-eski-metinler/images/M%C3%96-Haz%C4%B1rl%C4%B1k-21/y%C3%B6ney%C3%96rne%C4%9Fi.png"&gt;
&lt;p&gt;&lt;a class="footnote-reference" href="https://d-k-e.github.io/yapayzeka-eski-metinler/posts/makine-ogrenimine-hazirlik-21-dogrusal-cebir-1/#id4" id="id1"&gt;[2]&lt;/a&gt;
Resimdeki "a" yöneyimizin &lt;em&gt;vardığı&lt;/em&gt; dolayısıyla onu tayin eden noktayı belirtiyor.
63° olarak belirtilen yöneyin yönü.
Doğru olarak çizilen alansa yöneyin büyüklüğünü temsil ediyor.&lt;/p&gt;
&lt;p&gt;Yöneyler açık olarak ifade edildiklerinde genelde şu şekilde yazılırlar.
Diyelim ki elimizde bir "a" yöneyi olsun &lt;span class="math"&gt;\(a = [a_1, a_2, a_3,{\dots}, a_n ]\)&lt;/span&gt;.
"a"'nın altına yazılanlar elemanların numarası, yani a yöneyinin birinci elemanı, ikinci elemanı, gibi.
Bazı kitaplarda A noktasından B noktasına doğru olan bir yöney için &lt;span class="math"&gt;\(\vec{AB}\)&lt;/span&gt; gibi ifadeler de kullanılıyor.
Bazen yöneyi dikine yazdıklarını da gördüm. Örneğin:&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
a = \left[
\begin{array}{r}
 a_1 \\
 a_2 \\
 a_3 \\
 \vdots \\
 a_n
 \end{array}
\right]
\end{equation*}
&lt;/div&gt;
&lt;p&gt;Yöneylerin dizinlenmesinde kullanılan bir takım uzlaşımlar var.
Örneğin, yöneyin ikinci, beşinci ve yirmi sekizinci elemanlarını ayırmak istersek, bunun için başta bu eleman numaralarının olduğu bir küme oluşturuyoruz.
Örneğin "k" kümesi, yani &lt;span class="math"&gt;\(k = { 2, 5, 28 }\)&lt;/span&gt;.
Sonrasında da bu kümenin adını tıpkı diğer elemanları ifade ederken kullandığımız gibi yöneyin adının altına koyuyoruz, yani &lt;span class="math"&gt;\(a_k\)&lt;/span&gt;.
Hariç olan elemanları kast ettiğimizde eksi işaretini kullanıyoruz.
Örneğin ikinci elemanlar hariç, yöneyin bütün elemanları gibi bir ifade, şöyle oluyor &lt;span class="math"&gt;\(a_{-2}\)&lt;/span&gt;.
"k" kümesine dahil olmayan elemanların hepsi gibi ifadeler de yine benzer bir şekilde &lt;span class="math"&gt;\(a_{-k}\)&lt;/span&gt; ifade ediliyor.&lt;/p&gt;
&lt;!-- yöneylerin dizinlenmesi sayfa 32, resmi küçült renklerini değiştir --&gt;
&lt;/div&gt;
&lt;div class="section" id="dizeyler"&gt;
&lt;h2&gt;Dizeyler&lt;/h2&gt;
&lt;p&gt;Dizeyler bayağı meşhur, filmini bile çektiler. İsminden anlaşılacağı üzere yatay ve dikey dizilerden oluşan, dolayısıyla iki boyutlu, sayı dizinidir.
Genellikle boyutları y x d ifadesiyle verilir.
Bu ifade y, satıra, d sütun olarak okunur &lt;a class="footnote-reference" href="https://d-k-e.github.io/yapayzeka-eski-metinler/posts/makine-ogrenimine-hazirlik-21-dogrusal-cebir-1/#id3" id="id2"&gt;[1]&lt;/a&gt;.
Örneğin 23 satırlı ve 4 sütunlu bir K dizeyi için kullanılan ifade şudur: &lt;span class="math"&gt;\(K^{23x4}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Dizeyler ve onlarla ilgili işlemler Makine Öğreniminde çok sık kullanılıyor, bundan dolayıdır ki numpy, scipy filan gibi kütüphaneler, dizey işlemlerini eniyilemek için bir hayli uğraşıyorlar.
Dizeydeki bir elemanı ifade etmek istediğimizde onun satır ve sütun numarasını veririz&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Örneğin &lt;span class="math"&gt;\(K_{12,2}\)&lt;/span&gt; ifadesi K dizeyinin 12. satırı üzerinde 3. sütunun altına denk gelen elemanı ifade etmektedir.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Bir &lt;strong&gt;satırdaki&lt;/strong&gt; elemanların tamamını ifade etmek istediğimiz zaman sütun numarası yerine ":" koyulur.&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Örneğin &lt;span class="math"&gt;\(K_{3,:}\)&lt;/span&gt; ifadesi K dizeyinin 3. satırındaki bütün elemanları ifade eder.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Bir &lt;strong&gt;sütundaki&lt;/strong&gt; elemanların tamamını ifade etmek istediğimiz zaman satır numarası yerine ":" koyulur.&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Örneğin &lt;span class="math"&gt;\(K_{:,3}\)&lt;/span&gt; ifadesi K dizeyinin 3. sütunundaki bütün elemanları ifade eder.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Bazı durumlarda dizeyde erişmek istediğimiz elemanlar bir ifadenin sonucudurlar.
İfadeden kastım, 3'ün katı olan satırların 2.sinden 3. sütuna tekabül eden eleman gibi şeyler.
Bunlar genelde &lt;span class="math"&gt;\(f(K)_{y,d}\)&lt;/span&gt; şeklinde temsil edilir.
Bu ifade şu şekilde okunur, K dizeyine f işlemini yap, oradaki satır ve sütunu al.
f işleminden kastım, yukarıdaki 3'ün katı filan muhabbeti gibi olan ifadeler.
Tam öyle olmak zorunda değil tabi ama ona benzer dizey değerlendirmesi yapan ifadeler.&lt;/p&gt;
&lt;p&gt;Sıklıkla bahsedeceğimiz dizey işlemleri şunlar: dizey toplamı, sayıl çarpımı, dizey çaprazlama, dizey çarpımı.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="gereyler"&gt;
&lt;h2&gt;Gereyler&lt;/h2&gt;
&lt;p&gt;Gereyler aslında dizeyler gibi, sadece çok boyutlular.
Nasıl K dizeyindeki bir elemanı tayin etmek için eksenler üzerindeki konumunu K'nin altına yazıyorduk, gereylerde de benzer bir sistem var.
Örneğin 7 boyutlu, yani eksenli bir G gereyindeki elemanı belirtmek için şöyle bir ifade kullanırız &lt;span class="math"&gt;\(G_{j,o,r,m,v,r,x}\)&lt;/span&gt;, tabi burada j, o, r, m, v, ve x'in, sayma sayıları kümesinin elemanı olduğunu kabul ediyoruz.&lt;/p&gt;
&lt;p&gt;Bu yazıyı burada bitiriyorum.
Gördüğümüz matematiksel kavramlar bundan sonrası için temel teşkil ediyor.
Bir sonraki yazıda bunlarla yapılan işlemleri anlatmaya çalışacağım.
Anlaşılmayan bir şey varsa, ya da eklemek istediğiniz bir şey varsa lütfen yorumlarda belirtin.&lt;/p&gt;
&lt;p&gt;Sağlıcakla,&lt;/p&gt;
&lt;p&gt;Kaan&lt;/p&gt;
&lt;div class="section" id="notlar"&gt;
&lt;h3&gt;Notlar&lt;/h3&gt;
&lt;table class="docutils footnote" frame="void" id="id3" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label"&gt;&lt;col&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="https://d-k-e.github.io/yapayzeka-eski-metinler/posts/makine-ogrenimine-hazirlik-21-dogrusal-cebir-1/#id2"&gt;[1]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;y, yi yatay, d'yi dikey gibi de okuyabilirsiniz, yani yataya dikey.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id4" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label"&gt;&lt;col&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="https://d-k-e.github.io/yapayzeka-eski-metinler/posts/makine-ogrenimine-hazirlik-21-dogrusal-cebir-1/#id1"&gt;[2]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;Resimin temeli Jakob Scholbach'a aittir, üzerindeki değişiklikler bana ait, &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Vector_space#/media/File:Vector_components.svg"&gt;orjinali&lt;/a&gt;.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;</description><category>dizey</category><category>gerey</category><category>makine öğrenimi</category><category>mathjax</category><category>sayıl</category><category>yöney</category><guid>https://d-k-e.github.io/yapayzeka-eski-metinler/posts/makine-ogrenimine-hazirlik-21-dogrusal-cebir-1/</guid><pubDate>Mon, 29 May 2017 23:53:12 GMT</pubDate></item><item><title>Yapay Zeka ve Derin Öğrenime Giriş 1.3</title><link>https://d-k-e.github.io/yapayzeka-eski-metinler/posts/yapay-zeka-ve-derin-ogrenime-giris-13/</link><dc:creator>Kaan Eraslan</dc:creator><description>&lt;div&gt;&lt;p&gt;Merhaba Arkadaşlar,&lt;/p&gt;
&lt;p&gt;Bir &lt;a class="reference external" href="https://d-k-e.github.io/yapayzeka-eski-metinler/posts/yapay-zeka-ve-derin-ogrenime-giris-2/"&gt;önceki yazımda&lt;/a&gt; &lt;em&gt;Temsil Öğrenimi&lt;/em&gt; veya diğer bir adıyla &lt;em&gt;Nitelik Öğrenimi&lt;/em&gt; konusuna değinmiştim.
Otomatik kodlayıcıların aldıkları işlevlerden ve temsilde açığa çıkan değişiklik unsurlarıyla, gözlemlenenlerin ayrıştırıcı özellikleri arasındaki ilişkiden bahsetmiştim.
Ayrıştırıcı özelliklerin arasındaki karşılıklı etkileşim dolayısıyla temsil öğrenimindeki aşılması güç gözüken bir sorun olan değişiklik unsurlarının birbirinden ayrıştırılması işlemini açıklamaya çalıştım.&lt;/p&gt;
&lt;p&gt;Bu yazıda, önceki yazıda duyurduğum gibi &lt;em&gt;Derin Öğrenimin&lt;/em&gt; bahsettiğim kavramlarla ilişkisine ve yukarıda belirttiğim probleme nasıl bir çözüm getirdiğine değineceğim.
Bu giriş yazı dizisinin son yazısı olduğu için, kavramlarla aşina olmayanlar için serinin ilk iki yazısına da göz atmalarını tavsiye ederim, aksi takdirde bazı şeyler havada kalacaktır.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Derin Öğrenimin&lt;/em&gt; yaptığı karmaşık temsilleri daha basit temsiller cinsinden ifade etmeye çalışmaktır.
Örneğin, beyaz bir tahtaya çizilmiş bir üçgeni düşünelim.
Üçgene baktığımızda gördüğümüz önce beyazdan farklı olandır.
Sonrasında bu farklı olanın düz çizgilerden oluştuğunu fark ederiz.
Ardından bu düz çizgilerin köşeler oluşturduğunu fark ederiz.
Nihayetinde oluşan köşelerin sayısı bize üçgeni verir.
Bu işleyiş derin öğrenim sürecinde makinenin işleyişine benzerdir.
Makine başta imgecik değerlerinden, beyaz olmayanları gruplar.
Sonrasında gruplananların pozisyonlarını karşılaştırarak alarak onların kenar mı köşe mi olduğunu belirler.
Son olarak da köşe sayısını hesaplar ve ilgili köşe sayısına tekabül ettiği kendisine verilmiş sonucu size sunar.&lt;/p&gt;
&lt;p&gt;O halde fark etmiş olabileceğiniz üzere burada işleyen imgecik değerlerinde açıkça gözlemediğimiz 4-5 tane kavram var.
Siyah, beyaz, düz çizgi, kenar, köşe, köşe sayısı.
Siyahı, beyaz olmayan diyerek, ve imgecik değerlerindeki farklılıktan yakaladık diyelim.
Beyaz olmayan imgeciklerin düz bir çizgi oluşturduğunu ifade edebilmemiz için, bu imgeciklerin konumu hakkında bize yargı veren bir model olması lazım.
Bu açıkça görüldüğü üzere ne üçgenle ne de imgeciklerin kendisiyle doğrudan ilişkili bir yapı, sadece belirli konumlarda olanların düz olmaya tekabül ettiğini belirten bir model.
Bu modelin elimizdeki üçgen problemine uygulanışında modele sunulan imgeciklerin konumu, ancak salt model açısından bakıldığında konumu verilen araba tekerleği, havadaki uçaklar, ya da endoplazmik retikulumlarda olabilirdi.
Aynı durum kenar, köşe kavramları içinde geçerli, yani bunlar da üçgen mahsus olmayan, imgeciklerle de doğrudan bir bağlantısı olmayan kavramlar.
Eldeki örnekte düz çizgilerin başladıkları ve bittikleri yerler olarak tanımlanıyor olmalarında ne üçgene ne de imgeciklere mahsus bir durum var.
Buna karşın, köşe sayısı ve üçgen arasındaki ilişki bir hayli doğrudan. O kadar ki bunun üçgen üzerinden modellenmiş bir nitelik olduğu fark ediliyor.
Makine elimizdeki örnekte bahsettiğimiz aşamalardan geçerek ne yapmış oldu peki ?
Çok basit, modeller arasındaki bir hiyerarşiyi takip ederek, yani onların ilgilendiği değerlerin hesaplanışında bir öncelik sonralık ilişkisi güderek, örneğin, önce siyah-beyaz, sonra çizgi, sonra kenar-köşe, vs. gibi, ham veriden, yani imgeciklerden, yakalamak istediğimiz varlığın ayrıştırıcı özelliğini, üç köşeli olmak, buldu.&lt;/p&gt;
&lt;p&gt;Bu yaklaşımdaki esas nokta, farklı modeller tarafından hesaplanan sonuçların daha sonra kendilerine atıfta bulunulabilecek şekilde saklanmaları, bu sistemin kendi kendisini değerlendirebilmesini sağlayan yegane özellik.
Elimizdeki örnekte fark etmesi birazcık zor olmakla birlikte, diyelim ki ABC üçgeninin BC kenarının ortasında ufak bir boşluk var.
Silgi çarpmış, kolumuz değmiş, vs. herhangi bir şey olabilir.
Bu şartlar altında, üçgeni yakalamaya çalışan sistemimizin bu durumda çalışmaya devam etmesi, ve o boşluğu, kenarların ortasındaki boşluk olarak temsil edebilmesi lazım.
Modellerin sonuçlarının atıfta bulunulabilmesi burada devreye giriyor.
Elimizdeki örnekte makine diyelim ki düz çizgileri saptadı, ortaya açık bir şekil çıktı, dolayısıyla kenar diye bir şeyden söz edemememiz lazım.
Daha sonraki aşamada makine köşeleri ve köşe sayısını hesapladı ve şeklin üç köşe sayısı şartını sağladığını hesapladı.
Bu hesap ışığında makine, daha önceki model tarafından verilen açık şekil olmak sonucuna tekrar dönebilir, ve açıklık belirten değişiklik unsurunu, makineye daha öncesinden verdiğimiz talimatlar ışığında, görmezden gelebilir, veya bu sonucun kapsamını daraltabilir, yani örneğin şekil açıktır yerine çizgi bir nokta da kesilmiştir sonucunu sunabilir vs.&lt;/p&gt;
&lt;p&gt;Bu yöntemin derin öğrenim olarak ifade edilmesinin sebebi de, girdideki temsil ile çıktıdaki temsil arasında birbirinden görece bağımsız modeller tarafından üretilen temsillerin olması.
Derin Öğrenim algoritmalarını birer merdiven olarak da düşünebilirsiniz.
Her basamak aslında bir basamak, o basamağı bir başka basamağın üstüne ya da altına koyduğunuz için yukarıya ya da aşağıya doğru giden bir basamak. Kendi başına bıraksanız, yani merdivenden çıkarsanız basamağı ve yere koysanız, öyle ufak bir yükselti olur.&lt;/p&gt;
&lt;p&gt;Derin öğrenim modellerinin, derinlik ölçümü için kullanılan, temelde iki yaklaşım var.
Birincisi, bir derin öğrenim modelinin değerlendirilebilmesi için gerekli talimatların uzunluğu.
İkincisiyse, birbirleriyle ilişkilenen kavramların temsilini sunan çizgenin derinliği.
İlki hangi işlemin adım olarak sayılacağına göre değişiklik gösterir.
Kullandığımız modellerden birinin K-Ortalamalar Kümesi algoritması olduğunu düşünelim.
Bu algoritma bilindiği üzere aslında iki aşamalıdır: Merkezlere eleman tayin etme ve elemanların pozisyonlarını eniyileme.
Birinci kriter ışığında derinliğimiz bu iki aşamayı ayrı ayrı saymak ya da bu iki aşamayı aynı algoritmaya tabi olduğu için bir olarak saymak bağlamında değişiklik gösterecektir.
İkinci kriterle konuya yaklaşıldığı zamansa ortaya yukarıda üçgen için tarif ettiğim modele benzer bir model ortaya çıkıyor.
Elimizde, örneğin, düz çizgi, kenar, köşe gibi kavramlar var ve derinlik bunların birbiriyle olan ilişkilerini temsil eden çizgede gözleniyor.
Bu yaklaşımdaki dikkat edilmesi gereken noktaysa, kavramlar arasındaki ilişkilerden çıkan çizgedeki derinliğin, hesaplanma sürecini ifade eden çizgenin derinliğinden bir hayli farklı olması.&lt;/p&gt;
&lt;p&gt;Bu iki yaklaşımın ikisi de eşit derecede doğru ve geçerli, zira kişiler kendi modellerini kurgularken farklı birimleri temel alıyorlar.
Bir modelin derin olarak adlandırılabilmesi için de uzlaşılagelmiş bir ölçüm yok. O halde &lt;em&gt;Derin Öğrenim&lt;/em&gt; nedir ?
Tek cümleyle özetleyecek olursak, derin öğrenim, dünyayı içiçe geçmiş hiyerarşik temsiller şeklinde kurgulayarak karmaşık kavram ve temsilleri, daha basit kavram ve temsiller aracılığıyla hesaplayan, makine öğrenimi alanıdır.&lt;/p&gt;
&lt;p&gt;Bu yazıyı burada noktalıyorum ve böylelikle Derin Öğrenime Giriş serisini tamamlamış oluyorum.
Bundan sonraki seri, derin öğrenim algoritmalarını anlamak için olmazsa olmaz olan doğrusal cebir üzerine olacak.
Anlaşılmayan, ya da çok açık gözükmeyen noktaları lütfen yorumlarda belirtin.
Elimden geldiğince açıklamaya çalışırım.&lt;/p&gt;
&lt;p&gt;Sağlıcakla,&lt;/p&gt;
&lt;p&gt;Kaan&lt;/p&gt;&lt;/div&gt;</description><category>derin-öğrenim</category><category>makine öğrenimi</category><category>yapay-zeka</category><guid>https://d-k-e.github.io/yapayzeka-eski-metinler/posts/yapay-zeka-ve-derin-ogrenime-giris-13/</guid><pubDate>Sun, 28 May 2017 01:52:32 GMT</pubDate></item><item><title>Yapay Zeka ve Derin Öğrenime Giriş - 1.1</title><link>https://d-k-e.github.io/yapayzeka-eski-metinler/posts/yapay-zeka-ve-derin-ogrenime-giris-1/</link><dc:creator>Doğu Kaan Eraslan</dc:creator><description>&lt;div&gt;&lt;p&gt;Merhaba arkadaşlar,&lt;/p&gt;
&lt;p&gt;Bu yapay zeka ve derin öğrenim ile ilgili yazmaya başladığım serinin ilk bölümü. Temel olarak kullandığım kaynak &lt;a class="citation-reference" href="https://d-k-e.github.io/yapayzeka-eski-metinler/posts/yapay-zeka-ve-derin-ogrenime-giris-1/#deeplearning2016" id="id1"&gt;[DeepLearning2016]&lt;/a&gt;. Bu bölümde:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
- Yapay zeka çalışmaları nedir ?
- Hangi sorunlara cevap vermeye çalışmaktadır ?
- İçindeki çalışma alanları nelerdir ?
&lt;/pre&gt;
&lt;p&gt;Gibi sorulara değineceğim. Sonraki yazılarda daha teknik konulara yer yer algoritmalara da gireceğim. Bu yazıda bahsettiğim konular, referans verdiğim kaynağın 1. bölümüne tekabül etmektedir.&lt;/p&gt;
&lt;p&gt;Yapay zeka esasen fark etme ve tanımlama sorunsalı üzerinden okunabilecek bir alan. Bir şeyleri 5 duyudan ve onları sentetize eden bir beyinden yoksun bir varlığa fark ettirme sorunsalı. Fark etmenin gerçekleşmesi içinde yapılması gerekense, fark edilecek şeyin duyusal içerikten bağımsız bir biçimde tanımlanması.&lt;/p&gt;
&lt;p&gt;Bilgisayarlar genel olarak, soyut kuralları takip etme işinde bizden daha iyiler. Bunun güzel bir örneği, bizden daha hızlı matematik işlemi yapabiliyor olmalarında, bir başka örneği yine bizden daha iyi satranç oynuyor olmalarında. Counter Strike vs gibi oyunlarla ilgilenen arkadaşların, internet kafede hedef botu kullanan adamı dövmesindeki sebepte yine bilgisayarın verili kuralları bizden daha iyi uygulayabiliyor olmasında.&lt;/p&gt;
&lt;p&gt;Ancak bilgisayarlar 5 duyu gerektiren işlerde açık ara kötüler. Örneğin soru sorana cevap verme, karşıdan karşıya geçerken gelen arabayı görüp durma vs gibi işleri beceremiyorlar, zira bu işler çok fazla farklı türden veriyi birbiriyle ilişkilendirmiş olarak zihnimizde barındırmamız sayesinde mümkün oluyor. Biz bu işleri otomatik yapıyoruz ve aslında ne kadar karmaşık bir ilişkiler ağının ürünü olduğunun genelde farkında değiliz. Çok fark etmeye başladığımız zaman da deliriyoruz zaten, ancak şu da bir gerçek ki bilgisayarın günlük hayatımızı gerçekten kolaylaştırabilmesi, büyük oranda bu cins işleri yapabilmesine bağlı. Yani siz dizi izlerken makinenin, akşam yemeği, ev temizliği, hatta ofis işlerinizin belirli bir bölümü gibi işlevleri gerçekleştirebilmesi için, bu 5 duyu gerektiren işlerde de sonuç alabilmeleri gerekiyor.&lt;/p&gt;
&lt;p&gt;İşte yapay zeka çalışmaları makinenin bu işleri yapabilmesini sağlayacak yöntemleri araştırıyor.
Denen yöntemlerden biri, makinenin dünyaya ilişkin bilmesi gereken her şeyi kodlamaya çalışmak, ki buna yapay zekaya bilgi temelli yaklaşım &lt;a class="footnote-reference" href="https://d-k-e.github.io/yapayzeka-eski-metinler/posts/yapay-zeka-ve-derin-ogrenime-giris-1/#id8" id="id2"&gt;[1]&lt;/a&gt; deniyor. Siz bilgileri anlamsal içerikten yoksun bir dille ifade etmeye çalışıyorsunuz. Bilgisayarda genel mantık çerçevesinde dizayn edilmiş çıkarım kurallarını kullanarak, kendisine gelen bilgiden çıkarımlar yapıyor. Bu çok tutmadı, zira varolanı anlamdan yoksun bir dille ifade etmek hem bizim çok iyi yapamadığımız bir şey, hem de çok ağır işleyen bir süreç.&lt;/p&gt;
&lt;p&gt;Her şeyin el ile kodlanması gerektiği sistemlerde karşılaşılan güçlükler,bizi makinelerin ham haldeki veriden kendilerinin tekrar eden kalıpları çıkarsamasını sağlayacak sistemler yaratmaya yöneltti. Bu minvalden gelen çalışmalara da genel adıyla makine öğrenimi &lt;a class="footnote-reference" href="https://d-k-e.github.io/yapayzeka-eski-metinler/posts/yapay-zeka-ve-derin-ogrenime-giris-1/#id9" id="id3"&gt;[2]&lt;/a&gt; alanında yapılan çalışmalar deniyor. Bu alanda yürütülen çalışmaların günlük hayattaki etkileri daha gözlemlenebilir durumda. Örneğin Naive Bayes algoritmasını kullanarak sahte e-postaları ayırt edebiliyoruz, ya da Doğrusal Bağlanımları kullanarak elimizdeki malzeme stoklarını ne zaman yenilememiz gerektiğine dair akıl yürütmeler yapabiliyoruz, veya Netflix gibi büyük şirketler çok basit K-Ortalamalar Kümesi gibi gruplama algoritmalarıyla sizin hangi filmlerden hoşlanabileceğiniz size sunuyorlar &lt;a class="citation-reference" href="https://d-k-e.github.io/yapayzeka-eski-metinler/posts/yapay-zeka-ve-derin-ogrenime-giris-1/#algoritmalar" id="id4"&gt;[Algoritmalar]&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Bu yaklaşım iyi hoş ama önemli bir sorunu var, o da verinin temsil &lt;a class="footnote-reference" href="https://d-k-e.github.io/yapayzeka-eski-metinler/posts/yapay-zeka-ve-derin-ogrenime-giris-1/#id10" id="id5"&gt;[3]&lt;/a&gt; edilmesi gerekliliği. Yukarıda bahsettiğim algoritmaların işleyebilmesi için, verinin belirli işlemlerden geçmesi gerekiyor. Bu çok basit bir biçimde bir metni boşlukları kullanarak, kelimelere ayırmak olabileceği gibi, kelimelerin belge içindeki sıklığı kere kelimelerin içinde görüldüğü belge sayısının kesri, boyutlarından oluşan uzunluğu standartlaştırılmış belge yöneyleriyle kosünüs benzerliği hesapları yapmak gibi görece daha karmaşık işlemleri de kapsayabiliyor &lt;a class="citation-reference" href="https://d-k-e.github.io/yapayzeka-eski-metinler/posts/yapay-zeka-ve-derin-ogrenime-giris-1/#tf-idf" id="id6"&gt;[TF-IDF]&lt;/a&gt;. İşlem görmüş ham veri içerisinde dikkate alınan her bir parçaya nitelik &lt;a class="footnote-reference" href="https://d-k-e.github.io/yapayzeka-eski-metinler/posts/yapay-zeka-ve-derin-ogrenime-giris-1/#id11" id="id7"&gt;[4]&lt;/a&gt; deniyor. Yani ham veriye dair makinenin çıkarımlar yapabilmesini istiyorsanız onu bir nitelikler bütününe dönüştürmeniz lazım.&lt;/p&gt;
&lt;p&gt;Üzerinde çalıştığınız problemin gerektirdiği verilerin hangi özelliğinin çözüme ilişkin olduğunu ve bu özelliğin ne şekilde bir niteliğe dönüştürebileceğini saptamanız gerekiyor. Bu bir hayli meşakatli bir iş. Örneğin, elinizde 100 bin tane kırmızı ışıkta geçen araba resmi var. Bu arabalara ceza kesilebilmesi için, plakalarının fotoğraflarda ayrıştırılabilmesi gerekiyor. Bilgisayar için arabanın tamponu ile plakası arasında bir fark yok. İkisi de imgecik. Örneği ilgili terimlerle ifade edersek:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
- Problem: Işıktan geçen araba resminden plaka alma
- Özellik: Plaka: Beyaz bir dikdörtgen, üstünde siyahla yazılmış rakamlar ve sayılar var, bazılarında tire işareti de oluyor.
- Temsil: İmgecikler.
&lt;/pre&gt;
&lt;p&gt;Çözüm ne peki ? Temsilden özelliği türetmemizi sağlayacak nitelikleri ayrıştırmakta. Bunu nasıl yapacağız ? İşte makine öğreniminin temel sıkıntısı burada yatıyor.&lt;/p&gt;
&lt;p&gt;Bu yazıyı burada noktalıyorum, zira ara vermek için güzel bir nokta.
Bir &lt;a class="reference external" href="https://d-k-e.github.io/yapayzeka-eski-metinler/posts/yapay-zeka-ve-derin-ogrenime-giris-2/"&gt;sonraki yazımda&lt;/a&gt; &lt;em&gt;Temsil Öğrenimi&lt;/em&gt; ya da diğer bir adıyla &lt;em&gt;Nitelik Öğrenimini&lt;/em&gt; açıklamaya çalışacağım.
Çok katmanlı temsil gruplamalarından, değişiklik unsurlarından ve bunların öğrenimdeki rollerinden bahsedeceğim. Üçüncü yazımdaysa &lt;em&gt;Derin Öğrenimin&lt;/em&gt; bu bahsettiğim kavramlarla olan ilişkisine, ve &lt;em&gt;derinliğin&lt;/em&gt; nereden geldiğine değineceğim.&lt;/p&gt;
&lt;p&gt;Sağlıcakla,&lt;/p&gt;
&lt;p&gt;Kaan&lt;/p&gt;
&lt;div class="section" id="terimler"&gt;
&lt;h2&gt;Terimler&lt;/h2&gt;
&lt;table class="docutils footnote" frame="void" id="id8" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label"&gt;&lt;col&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="https://d-k-e.github.io/yapayzeka-eski-metinler/posts/yapay-zeka-ve-derin-ogrenime-giris-1/#id2"&gt;[1]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;Bilgi Temelli Yaklaşım: Makinenin dünyaya ilişkin bilmesi gereken her şeyi elle kodlamaya çalışmak.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id9" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label"&gt;&lt;col&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="https://d-k-e.github.io/yapayzeka-eski-metinler/posts/yapay-zeka-ve-derin-ogrenime-giris-1/#id3"&gt;[2]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;Makine Öğrenimi: Makinenin ham veriden tekrar eden kalıplar çıkarsaması.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id10" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label"&gt;&lt;col&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="https://d-k-e.github.io/yapayzeka-eski-metinler/posts/yapay-zeka-ve-derin-ogrenime-giris-1/#id5"&gt;[3]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;Temsil: Verinin sayısal ortamdaki hali.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id11" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label"&gt;&lt;col&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="https://d-k-e.github.io/yapayzeka-eski-metinler/posts/yapay-zeka-ve-derin-ogrenime-giris-1/#id7"&gt;[4]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;Nitelik: Temsilde bir özelliği ayrıştırmaya yarayan ölçülebilir yapı.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class="section" id="notlar"&gt;
&lt;h2&gt;Notlar&lt;/h2&gt;
&lt;table class="docutils citation" frame="void" id="deeplearning2016" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label"&gt;&lt;col&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="https://d-k-e.github.io/yapayzeka-eski-metinler/posts/yapay-zeka-ve-derin-ogrenime-giris-1/#id1"&gt;[DeepLearning2016]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;Goodfellow I.,Y. Bengio, Deep Learning, Cambridge, 2016.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils citation" frame="void" id="algoritmalar" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label"&gt;&lt;col&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="https://d-k-e.github.io/yapayzeka-eski-metinler/posts/yapay-zeka-ve-derin-ogrenime-giris-1/#id4"&gt;[Algoritmalar]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;Bahsettiğim algoritmaları açıklayan yazılar da yayımlayacağım.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils citation" frame="void" id="tf-idf" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label"&gt;&lt;col&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="https://d-k-e.github.io/yapayzeka-eski-metinler/posts/yapay-zeka-ve-derin-ogrenime-giris-1/#id6"&gt;[TF-IDF]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;Kabaca tarifini yaptığım algoritmanın adı genellikle arama motorlarında kullanılan bir sıralama algoritması. İlk bölümü ts-tbs, açılımı, terim sıklığı-ters belge sıklığı algoritması (ingilizcesi t(erm) f(requency)-i(nverse) d(ocument) f(requency)), ikinci bölümüyse, kosünüs benzerliği. Bu ikisi arama motorlarındaki 'buna benzer sayfaları göster' gibi işlemlerin gerçekleşmesini sağlıyor. Bu algoritmayı açıklayan yazıları da ileride paylaşacağım.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;&lt;/div&gt;</description><category>derin-öğrenim</category><category>makine öğrenimi</category><category>yapay-zeka</category><guid>https://d-k-e.github.io/yapayzeka-eski-metinler/posts/yapay-zeka-ve-derin-ogrenime-giris-1/</guid><pubDate>Fri, 26 May 2017 00:13:15 GMT</pubDate></item></channel></rss>